# Course topics

## 1. Introduction to Python and Numpy
**Lectures:**
1. [How to use Google Colab for Python programming?](https://www.youtube.com/watch?v=PVsS9WtwVB8)
2. [Python3](https://youtube.com/watch?v=V42qfAPybp8)
3. [Numpy](https://www.youtube.com/watch?v=Omz8P8n-5gY)
4. [Matplotlib & Plotly](https://youtu.be/aIzkkjRzVdA) 

**Notebooks:** 
1. [Python3](notebooks/python.ipynb)
1. [Numpy](notebooks/numpy.ipynb)
1. [Matplotlib & Plotly](notebooks/matplotlib_plotly.ipynb) 

**Optional:**
1. Practice Python at [codewars.org](https://www.codewars.com/)
1. [From Python to Numpy](https://www.labri.fr/perso/nrougier/from-python-to-numpy/)   
1. [100 numpy exercises](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises.ipynb) by Nicolas P. Rougier  

## 2. Introduction to deep learning (Sections 1.1, 1.2, 1.3, and 4.1)
**Lectures:**
1. [Difference between AI, ML, and DL](https://youtu.be/kd62-4_jNoA)
1. [Introduction to deep learning](https://youtu.be/DGXuhXMgOO8)
1. [The power of a hidden layer in neural networks](https://youtu.be/V9x7SY_4y8c)
1. [How does machine learning (or deep learning) work? The intuition](https://youtu.be/Bp7zjKWRhAw)
1. [The four branches of machine learning](https://youtu.be/FlhcbzT2RUU)
1. [Learning 'bleeding-edge' deep learning](https://youtu.be/X8sCDMrPhAo)

**Optional:** [Deep Learning In 5 Minutes | What Is Deep Learning?](https://youtu.be/1k37OcjH7BM)

## 3. Data representations & tensor operations (Sections 2.2, 2.3, and 2.4) 
**Lectures:**
1. [What are tensors? Matrix vs Tensor](https://youtu.be/7FeO4lqcNfA)
1. [Tensors reshape automatically](https://youtu.be/92gOeXFq2FA)
1. [Examples of 3D, 4D, and 5D tensors](https://youtu.be/8gOg4VNRUaY)
1. [The gears of neural networks: Tensor operations](https://youtu.be/rv9w4MfnWgQ)
1. [Geometric interpretation of deep learning](https://youtu.be/h30cyYjXFIU)

**Optional:** [Lecture on TF2 by Joshwa Gordon @ Google](https://youtu.be/5ECD8J3dvDQ)

## 4. Introduction to Keras (Sections 3.2 and 3.3) 
**Lectures:**
1. [Introduction to Keras](https://youtu.be/Ym34JC2UDFk)
1. [Keras is also an API in Tensorflow2](https://youtu.be/yNsQ6rqEcv4)
1. [Keras sequential vs functional API](https://youtu.be/EvGS3VAsG4Y)
1. [Diversity of thought is holding back AI & deep learning research](https://youtu.be/pXMFMs1ryy4)
1. [AlphaFold2: Example of the power of diversity](https://youtu.be/gg7WjuFs8F4)
1. [Splitting data into development set + (training & validation) and test set + Callbacks](https://youtu.be/OeZ6i-8xXwQ)
1. [Binary classification using feed-forward neural networks](https://youtu.be/cJ3oqHqRBF0)    

**Notebook:** [Binary classification using feed-forward neural networks](./notebooks/wine_quality.ipynb)

**Optional:** [Francois Chollet interview](https://youtu.be/Bo8MY4JpiXE)

## 5. Preparing images for deep learning (Sections 3.6.2, 5.2.4, and 5.2.5)
**Lectures:** 
1. [Image is all numbers](https://youtu.be/mjh5NIn1yHk) (watch the first five minutes only)
1. [Data generators and image augmentation](https://youtu.be/dSs3kjqvv_Q) 
1. [Image preprocessing](https://youtu.be/9_OFSSYcVWU)

**Notebook:** [Image preprocessing](./notebooks/Image_preprocessing.ipynb)

## 6. The convolution operation (Section 5.1.1) 
**Lectures:** 
1. [Our eye and human visual system: Biological inspiration for convolutional neural networks](https://youtu.be/nu9Jdvhe1Pk)
1. [Our eyes have blind spots](https://youtu.be/QXzgokis33I) / [article](https://lasikofnv.com/try-these-3-fun-tests-to-find-your-visual-blind-spot/)
1. [Feed-forward (dense) vs Convolutional Neural networks](https://youtu.be/aU6lRpMkBkE)
1. [Hulk vs. Ant Man](https://youtu.be/fNGSHrQDuA8)
1. [The convolution operation](https://youtu.be/C73AemPLnL8)
1. [A convolutional neuron (filter): An example](https://youtu.be/oqf79zcafao)
1. [The two main parameters of a convolutional layer](https://youtu.be/GeBh1yd_H_E)
1. [How to calculate the number of parameters in a convolutional neural network? Some examples](https://youtu.be/bikmA-VmSbY)
1. [Border effect, padding, and maxpooling](https://youtu.be/MTmn--tHbHs)
1. [Separable convolutions and dilated convolutions](https://youtu.be/vCJ4magCPts)
1. A practical example: [What can one convolutional neuron do? Detect a square.](https://youtu.be/A69TFtiOREU)
1. [Classify MNIST digits using a CNN](https://youtu.be/jd4-zRwYjDY)

**Notebooks**: 
1. [Detecting a square](./notebooks/Detect_a_square.ipynb)
1. [MNIST](./notebooks/MNIST.ipynb)

**Reading:** [Intuitively Understanding Convolutions for Deep Learning](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)

## 7. Activations & loss functions (Sections 4.5.5, and Table 4.1) 
**Lectures:**   

1. [How to choose the last layerâ€™s activation and loss in NN?]
1. [Softmax activation & other activations for deep neural networks]
1. [How to choose a loss function for a regression problem?]
1. [Categorial cross-entropy loss (softmax loss) for multi-class classification]
1. [How to choose a loss function for a regression problem?]
1. [How to choose an optimizer for a Tensorflow Keras model?]

## 8. Feature engineering (Section 4.3)

[slides](https://docs.google.com/presentation/d/14k2vUTlJThQ0u8RVc0C68_92K1Df5YW0v85C5w3nFe8/edit?usp=sharing) 

## 9. Overfitting, underfitting, & regularization (Sections 4.2 and 4.4) 
1. [The Blind Men and the Elephant](https://youtu.be/Vn9BUfUCL4I)
1. [Evaluating models]

- [slides](https://docs.google.com/presentation/d/1RyqzBPX5_Cbs_sCsEJLmYWWK7hbScr2jJABV6blFxRU/edit?usp=sharing)

## 10. Workflow of machine learning (Sections 4.5, 4.5.5, 4.5.6, and 4.5.7) - [slides](https://docs.google.com/presentation/d/1jhp6E1B0M0Adf9jfv8OGZu2nv0p9Y1AmMy3KrwTWLFc/edit?usp=sharing) / [cheatsheet](https://docs.google.com/presentation/d/1mT4aHk0yx9dwxrfnr1WBSKYjEheYhf8R_x0NegrUsto/edit?usp=sharing)

## 11. Classic CNN architectures (Sections 5.1.1, 5.1.2, and 7.1) 
- [slides](https://docs.google.com/presentation/d/1a5yeHRI_i0INatg9rLVpYuNTNvrxLCLxKH5_RISFwEY/edit?usp=sharing) / [notebooks](./notebooks/)

## 12. Deep learning practices (Sections 5.3, 5.3.1, 5.3.2, 5.4, 7.1.2, 7.1.3, 7.1.4, and 7.1.5) 
- [slides](https://docs.google.com/presentation/d/15qI0K9Sm4Ab1vp0x6fKyeCmweMZggTh237zfSxwj-B0/edit?usp=sharing)
1. [Multi-input and Multi-output models]
1. [Layer weight sharing (The Siamese LSTM)]
1. GPUs for deep learning - [slides](https://docs.google.com/presentation/d/1Jg-BOZBDfhBht_3Sf49ja8QrWK_QuX7pr1CQkAf2mcI/edit?usp=sharing)
1. Transfer learning
- [slides](https://docs.google.com/presentation/d/1OV2KDijNYVnwYUrpp0otFCGyt-mejSsvtArp3UyrMQM/edit?usp=sharing) / [notebook](./notebooks/Transfer_learning.ipynb)
1. [What is Explainable AI (XAI)?](https://vimeo.com/278690594)
1. [Techniques for interpreting a deep learning model]

**Reading:** [Neural Network Follies](https://neil.fraser.name/writing/tank/)

## 13. Limitations of deep learning & conclusions (Section 9.2)

**Lectures:**
1. [Goals of deep learning]
1. [Limitations of deep learning]

**Optional:** [Andrew Ng: Advice on Getting Started in Deep Learning](https://youtu.be/1k37OcjH7BM)

1. Capsule networks - [slides](https://docs.google.com/presentation/d/1stzUpXvI889j1sziwbStpDItTfvBJ2ylrnMAJAxzLlo/edit?usp=sharing)

